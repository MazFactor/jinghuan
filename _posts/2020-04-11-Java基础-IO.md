---
layout: post
title: Java基础-IO
categories: Java
description: Java IO
keywords: IO
---
计算机中运算和存储的数据最小单位是位（bit），它的值只可能是0或者1。但1 bit 的信息量太少了。要表示一个有用的信息，需要好几个bit一起表示。所以除了硬件层面存在1个比特位的寄存器，大多数情况下，**字节（byte）是数据最小的基本单位**。

计算机中的数据分为两类：数值类型和非数值类型

Java语言提供了八种基本类型。六种数值类型（四个整数型，两个浮点型），一种字符类型，还有一种布尔型。其中整型、浮点型、布尔型都是以二井制形式存储，而字符型则需要通过编码转换为二进制进行存储。详见另外一篇文章[计算机的基础数据类型](https://www.cnblogs.com/yilang/p/11139380.html)。

### 编码
#### 概念
编码，又称代码，是用预先规定的方法，将文字、数字或其他对象编成数码，或将信息、数据转换成规定的电脉冲信号。它在电子计算机、电视遥控和通讯等方面广泛使用。

在电子计算机中，将指令和数字实行编码后，适合计算机运行和操作。编码作为计算机书写指令的过程，是程序设计活动的一部分。在数字磁记录中，可按照一定的规则，进行输入信息序列向编码序列的过程转换。在遥控系统和通信系统中，采用编码步骤可提高传送的效率和可靠性。

将数据转换为编码字符，必要时又可编码成原来的数据形式。

#### 字符集与编码
各个国家和地区所制定的不同 ANSI 编码标准中，都只规定了各自语言所需的“字符”。比如：汉字标准（GB2312）中没有规定韩国语字符怎样存储。这些 ANSI 编码标准所规定的内容包含两层含义：

1.使用哪些字符。也就是说哪些汉字，字母和符号会被收入标准中。所包含“字符”的集合就叫做“字符集”。<br>
2.规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储，这个规定就叫做“编码”。

各个国家和地区在制定编码标准的时候，“字符的集合”和“编码”一般都是同时制定的。因此，平常所说的“字符集”，比如：GB2312、GBK、JIS 等，除了有“字符的集合”这层含义外，同时也包含了“编码”的含义。

“UNICODE 字符集”包含了各种语言中使用到的所有“字符”。用来给 UNICODE 字符集编码的标准有很多种，比如：UTF-8、UTF-7、UTF-16、UnicodeLittle、UnicodeBig 等。

如上所述，编码是依据预先规定的标准将某一对象信息变成计算机可识别的数码，因此，如果没有规定标准的编码方法，那么有这些独立的、不统一的编码规则实现的程序，将不具兼容性，易出现如乱码等由于编码格式一致或不兼容引起的问题。

#### ASCII
原本对于西方世界来讲，可能根本用不到“字符”这个东西。1个字节就解决全部问题了。因为一个字节8 bit，最多为2^8=256个符号编码。英语26个字母，再加几个常用符号，标点，256个码位足够了。这就熟悉的**ASCII码**。如下图，ASCII码一共收录了空格及94个“可印刷字符”。每个字母或标点占一个字节。简简单单一个表，就把所有编码都解决了。

![ASCII码表]({{assets_base_url}}/images/blog/Java基础/IO/ASCII码表.jpg)
<center>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">ASCII码表</div>
</center>

#### ISO/IEC 8859-1
但西方世界不光只有英语一门语言。什么德语，法语，西班牙语都有自己的特殊字母。但这也没什么大不了的。每个国家都可以定义属于自己语言的特殊编码标准，而且大小照样不超过256。因为ASCII码中本身就有很多空码位没有使用。比如**ISO/IEC 8859-n**系就是国际标准化组织定义的一系列8位字符集。其中最常见的**ISO/IEC 8859-1**就是法语，芬兰语所用的西欧字符集。也是每个字母或符号用1个字节表示，下面这张表解决战斗。

![ISO IEC 8859-1]({{assets_base_url}}/images/blog/Java基础/IO/ISO IEC 8859-1.jpg)
<center>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">ISO IEC 8859-1</div>
</center>

#### 中文编码
但26个字母到了中文，日语，韩语为代表的东亚象形文字面前就太小儿科了。汉字少说也有十万个。别说是8 bit，就算是16 bit（2^16=65536）也不一定够。如果说一个汉字代表一个“字符”，从这个时候开始，“字符”的概念开始凌驾于“字节”之上了。收到的每一个字节不能简单地解码成一个字母了，而是需要好几个字节组合成一个“汉字”。我国的汉字编码现行标准是GB18030，每个字可以由1个、2个或4个字节组成，编码空间有161万个字符。另一个中国常用编码集是Big5。

#### Unicode
在出现Unicode之前，几乎每一种文字都有一套自己的编码方式。同一段“字节流”，在美帝可能是"hello world"，到我们天朝就变成“锟斤拷” ，“烫烫烫”了。所以“Unicode”可谓大势所趋。它的理念非常简单：全世界每个不同语言的不同字符都统一编码，全球通行。最初，每个字符占用2个字节，总共2^16=65536个字符空间。比如，下面是“中国”两个字的Unicode代码。从第四版开始加入的“扩展字符集”开始使用4个字节（32 bit）编码。目前Unicode收录的字符规模大概在12万左右。

> 中 => 4e2d 000d<br>
> 国 => 000a 56fd

#### UTF-16
编码里最容易搞混的一件事就是：Unicode只是一套符号的编码。但计算机具体怎么读取这套编码，又是另外一件事。

比如既然Unicode常规字符集占用2个字节，系统可以每次老老实实读取两个字节。然后用一个特殊符号告诉系统某个字符属于附加字符集，需要再往后读2个字节。比如说Java系统默认的UTF-16就是就是这样编码解码的：

考虑下面这句话：

> I am 君山

![I am 君山]({{assets_base_url}}/images/blog/Java基础/IO/I am 君山.jpg)

Unicode字符集中：

> 君=541b。拆开存在两个字节里：“54”和“1b”。<br>
> 山=5c71。拆开存在两个字节里：“5c”和“71”。

是不是很朴素？

#### UTF-8
但上面UTF-16的缺点也很明显：就是所有英语字符“I am”也被迫用2个字节来编码。比如，

> I=49。在前面补零变成：“00”和“49”。

考虑到英语是使用最广泛的语言，用2个字节为1字节信息编码，浪费了内存空间。最好是让英语保持ASCII的编码，用1个字节，汉字等其他字符才用2个或更长的字节表示。这里就涉及到一个技术问题：怎么让系统知道一个字符是用1个还是2个还是3个字节编码的呢？这就是UTF-8做的事。

如下图所示，这里UTF-8可变长编码用到了一个小技巧：用几位冗余信息告诉系统，当前字符有没有结束，是不是还需要继续往下读下一个字节。

![UTF-8]({{assets_base_url}}/images/blog/Java基础/IO/UTF-8.png)
<center>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">UTF-8</div>
</center>

可以看到如果一个字节是以“0”开头的，说明是一个ASCII字符，只占一个字节。如果是“11”开头的，说明这个字符占用多个字节。后续每个“10”打头的字节都是这个字符的一部分。

下图演示了字符串“I am 君山”用 UTF-8 编码的结果：

![演变结果]({{assets_base_url}}/images/blog/Java基础/IO/演变结果.jpg)
<center>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">演变结果</div>
</center>

> 君 = 541b = 0101 0100 0001 1011 (Unicode)

需要用3个字节编码，把0101010000011011切成3部分变成：

> 0101 010000 011011 

分别套上UTF-8字符头：

> 1110 0101 10 010000 10 011011 = e5 90 9b

所以如上图所示，“君”字用UTF-8编码就成了：e5909b。

总而言之，一切都是字节流，其实没有字符流这个东西。字符只是根据编码集对字节流翻译之后的产物。

### Java I/O的编码系统
Java IO库有两个支系：

* 面向字节流的**InputStream**和**OutputStream**
* 面向字符的**Reader**和**Writer**

之前说了，字节流的InputStream和OutputStream是一切的基础。实际总线中流动的只有字节流。需要对字节流做特殊解码才能得到字符流。Java中负责从字节流向字符流解码的桥梁是：**InputStreamReader**和**OutputStreamWriter**

根据上面的编码规则，Reader返回的是一个解码后的Unicode码元。包装在一个int整型里返回。

```java
abstract int read();
```

也就是收到3个字节后，去掉UTF-8报头，拼装起来得到“君”字的Unicode码元。

> 1110 0101 10 010000 10 011011 => 0101 0100 0001 1011

然后包装在4个字节的int整型里返回：

> 0101 0100 0001 1011 => 0000 0000 0000 0000 0101 0100 0001 1011

write()方法是一个相反的编码过程：

```java
abstract void write(int c);
```

输入一个Unicode码元的int型，如果设定编码是UTF-8，内部会自动切割并添加报头。

以下是InputStreamReader和OutputStreamWriter的结构图：

![InputStreamReader和OutputStreamWriter类结构]({{assets_base_url}}/images/blog/Java基础/IO/InputStreamReader和OutputStreamWriter类结构.png)
<center>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #999;padding: 2px;">InputStreamReader和OutputStreamWriter类结构</div>
</center>

从图中可以猜到，实际负责编码和解码的是StreamDecoder类和StreamEncoder类。过程中必须指定使用的字符编码集Charset。所以InputStreamReader和OutputStreamWriter的构造器都带有Charset类型的参数。

> **InputStreamReader**(InputStream in, Charset cs)<br>
> **OutputStreamWriter**(OutputStream out, Charset cs)

如果没有指定编码集，将使用系统默认编码集。而我们经常使用的FileInputReader和FileOutputWriter就是InputStreamReader和OutputStreamWriter的派生类。

#### 内存String编码
另外一个要使用到Charset编码集的地方，是String的构造器和getBytes()方法。也可以通过参数控制具体使用的编码集。

```java
String s = "这是一段中文字符串"; 
byte[] b = s.getBytes("UTF-8"); 
String n = new String(b,"UTF-8");
```

#### nio的字符编码
另外nio包里的ByteBuffer的asCharBuffer()方法也可以实现字节流和字符流之间的转换。

```java
FileChannel fc=new FileInputStream(f).getChannel();
ByteBuffer bf=ByteBuffer.allocate(1024);
fc.read(bf);
bf.flip();
CharBuffer cf=bf.asCharBuffer();
```

但这里有个坑需要注意，asCharBuffer()方法，默认以UTF-16BE来解码byteBuffer里的字节。每个字符2字节。而String # getBytes()使用系统默认编码方式，大多数情况都不是UTF-16BE。所以经常CharBuffer里读取出来的会是乱码。